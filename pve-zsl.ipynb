{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 《Predicting Visual Exemplars of Unseen Classes for Zero-Shot Learning》\n",
    "\n",
    "[paper link](https://arxiv.org/abs/1605.08151)\n",
    "\n",
    "## Zero Shot Learning\n",
    "\n",
    "ZSL distinguishes between two types of classes: *seen* and *unseen*, where labeled examples are available for the seen classes only.\n",
    "\n",
    "大部分的ZSL采用两步：1.预测图像在semantic space的embedding；2.通过对比embedding和没见过的类的semantic representation，来预测类标。\n",
    "\n",
    "## approach\n",
    "\n",
    "![]()\n",
    "\n",
    "给定一个image的表示，即特征向量x，ZSL的核心问题是去学一个compatibility function：$g(φ(x),ψ(a))$。其中φ(x)将视觉特征映射到semantic embedding空间；ψ(a)将类别的语义信息a映射到semantic embedding空间；g(.,.)衡量二者的compatibility。\n",
    "\n",
    "**本方法的核心思想**：通过语义表示$a_i$可以很好地预测聚类的location。这个约束可以将所有embedded的视觉特征向量$φ(x_i)$确定为类标i。\n",
    "\n",
    "**具体方法**：1.学习从semantic representation去预测视觉标本（聚类的中心）的函数，即学习ψ(a)，$ψ(a)≈v_c$，$v_c=\\frac{1}{|I_c|}\\sum_{n∈I_c}Mx_n$，其中，$v_c∈\\mathbb R^d$，$i_c=\\{i:y_i=c\\}$，$M∈\\mathbb R^{d*D}，M是PCA映射矩阵$(具体的学习使用support vector regressor with RBF kernel)；2.利用预测获得的视觉标本作为训练数据，$\\hat {y}=\\underset{u}{argmin}dis_{NN}(Mx,ψ(a_u))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
